{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro to pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R2mkaNML6Y0",
        "outputId": "4fc748ff-b765-44ef-80c3-5e1c395ea831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-4.8923e-01, -6.4613e-01,  8.7147e-01],\n",
            "        [ 9.6278e-01, -5.4996e-01,  2.8750e-01],\n",
            "        [ 4.2678e-04,  1.6469e-01, -1.4208e+00]])\n",
            "torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# Import torch\n",
        "import torch\n",
        "\n",
        "# Create random tensor of size 3 by 3\n",
        "your_first_tensor = torch.randn((3, 3))\n",
        "\n",
        "# Calculate the shape of the tensor\n",
        "tensor_size = your_first_tensor.shape\n",
        "\n",
        "# Print the values of the tensor and its shape\n",
        "print(your_first_tensor)\n",
        "print(tensor_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix of ones with shape 3 by 3\n",
        "tensor_of_ones = torch.ones(3, 3)\n",
        "\n",
        "# Create an identity matrix with shape 3 by 3\n",
        "identity_tensor = torch.eye(3)\n",
        "\n",
        "# Do a matrix multiplication of tensor_of_ones with identity_tensor\n",
        "matrices_multiplied = tensor_of_ones @ identity_tensor\n",
        "print(matrices_multiplied)\n",
        "\n",
        "# Do an element-wise multiplication of tensor_of_ones with identity_tensor\n",
        "element_multiplication = tensor_of_ones*identity_tensor\n",
        "print(element_multiplication)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NyhhwSSL-YV",
        "outputId": "9de9e328-2eaa-4487-d9a3-980af14af3ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tensors x, y and z\n",
        "x = torch.rand(1000,1000)\n",
        "y = torch.rand(1000,1000)\n",
        "z = torch.rand(1000,1000)\n",
        "\n",
        "# Multiply x with y\n",
        "q = x@y\n",
        "\n",
        "# Multiply elementwise z with q\n",
        "f = z*q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "print(mean_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA6xLKClMB1n",
        "outputId": "c75a9deb-5ac9-4356-f200-333fa7b3f550"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(124.8458)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize x, y and z to values 4, -3 and 5\n",
        "x = torch.tensor(4., requires_grad =True)\n",
        "y = torch.tensor(-3., requires_grad=True)\n",
        "z = torch.tensor(5.,requires_grad=True)\n",
        "\n",
        "# Set q to sum of x and y, set f to product of q with z\n",
        "q = x+y\n",
        "f = q*z\n",
        "\n",
        "# Compute the derivatives\n",
        "f.backward()\n",
        "\n",
        "# Print the gradients\n",
        "print(\"Gradient of x is: \" + str(x.grad))\n",
        "print(\"Gradient of y is: \" + str(y.grad))\n",
        "print(\"Gradient of z is: \" + str(z.grad))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NH09LO7MHuY",
        "outputId": "9115d198-fff5-48c7-f641-87e45a0c859f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient of x is: tensor(5.)\n",
            "Gradient of y is: tensor(5.)\n",
            "Gradient of z is: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tensors x, y and z\n",
        "x = torch.rand(1000,1000,requires_grad=True)\n",
        "y = torch.rand(1000,1000,requires_grad=True)\n",
        "z = torch.rand(1000,1000,requires_grad=True)\n",
        "# Multiply tensors x and y\n",
        "q = x@y\n",
        "\n",
        "# Elementwise multiply tensors z with q\n",
        "f = z*q\n",
        "\n",
        "mean_f = torch.mean(f)\n",
        "\n",
        "# Calculate the gradients\n",
        "mean_f.backward()"
      ],
      "metadata": {
        "id": "M-aTTh3AMOKP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the weights of the neural network\n",
        "weight_1 = torch.rand(784, 200)\n",
        "weight_2 = torch.rand(200,10)\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(input_layer,weight_1)\n",
        "\n",
        "# Multiply hidden_1 with weight_2\n",
        "output_layer = torch.matmul(hidden_1,weight_2)\n",
        "print(output_layer)"
      ],
      "metadata": {
        "id": "AMyknpHxMRxV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "        self.fc1 =nn.Linear(784,200)\n",
        "        self.fc2 =nn.Linear(200,10)\n",
        "    def forward(self,x):\n",
        "        x=self.fc1(x)\n",
        "        x =self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "N4D1MhjVM6xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the first and second hidden layer\n",
        "hidden_1 = torch.matmul(input_layer, weight_1)\n",
        "hidden_2 = torch.matmul(hidden_1, weight_2)\n",
        "\n",
        "# Calculate the output\n",
        "print(torch.matmul(hidden_2,weight_3))\n",
        "\n",
        "# Calculate weight_composed_1 and weight\n",
        "weight_composed_1 = torch.matmul(weight_1,weight_2)\n",
        "weight = torch.matmul(weight_composed_1, weight_3)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input_layer, weight))"
      ],
      "metadata": {
        "id": "9nxnTzmcNIEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate non-linearity\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Apply non-linearity on the hidden layers\n",
        "hidden_1_activated = relu(torch.matmul(input_layer, weight_1))\n",
        "hidden_2_activated = relu(torch.matmul(hidden_1_activated, weight_2))\n",
        "print(torch.matmul(hidden_2_activated, weight_3))\n",
        "\n",
        "# Apply non-linearity in the product of first two weights. \n",
        "weight_composed_1_activated = relu(torch.matmul(weight_1, weight_2))\n",
        "\n",
        "# Multiply `weight_composed_1_activated` with `weight_3\n",
        "weight = torch.matmul(weight_composed_1_activated,weight_3)\n",
        "\n",
        "# Multiply input_layer with weight\n",
        "print(torch.matmul(input_layer, weight))"
      ],
      "metadata": {
        "id": "99Ocy2ELNLJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate ReLU activation function as relu\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Initialize weight_1 and weight_2 with random numbers\n",
        "weight_1 = torch.rand(4, 6)\n",
        "weight_2 = torch.rand(6, 2)\n",
        "\n",
        "# Multiply input_layer with weight_1\n",
        "hidden_1 = torch.matmul(input_layer,weight_1)\n",
        "\n",
        "# Apply ReLU activation function over hidden_1 and multiply with weight_2\n",
        "hidden_1_activated = relu(hidden_1)\n",
        "print(torch.matmul(hidden_1_activated, weight_2))"
      ],
      "metadata": {
        "id": "LfZ3gTP7NO8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the scores and ground truth\n",
        "logits = torch.tensor([[-1.2,0.12,4.8]])\n",
        "ground_truth = torch.tensor([2])\n",
        "\n",
        "# Instantiate cross entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Compute and print the loss\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "AD5ny4L_NPY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch and torch.nn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Initialize logits and ground truth\n",
        "logits = torch.rand(1,1000)\n",
        "ground_truth = torch.tensor([111])\n",
        "\n",
        "# Instantiate cross-entropy loss\n",
        "criterion =nn.CrossEntropyLoss()\n",
        "\n",
        "# Calculate and print the loss\n",
        "loss = criterion(logits,ground_truth)\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "BoKvgAvcNSVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the data to torch tensors and normalize it \n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "\t\t\t\t\t\t\t\ttransforms.Normalize((0.1307), ((0.3081)))])\n",
        "\n",
        "# Prepare training set and testing set\n",
        "trainset = torchvision.datasets.MNIST('mnist', train=True, \n",
        "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST('mnist', train=False, \n",
        "\t\t\t\t\t\t\t\t\t  download=True, transform=transform)\n",
        "\n",
        "# Prepare training loader and testing loader\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
        "\t\t\t\t\t\t\t\t\t\t  shuffle=True, num_workers=0)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
        "\t\t\t\t\t\t\t\t\t\t shuffle=False, num_workers=0)       "
      ],
      "metadata": {
        "id": "QBMESMyVNUcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the shape of the training set and testing set\n",
        "trainset_shape = trainloader.dataset.train_data.shape\n",
        "testset_shape = testloader.dataset.test_data.shape\n",
        "\n",
        "# Print the computed shapes\n",
        "print(trainset_shape, testset_shape)\n",
        "\n",
        "# Compute the size of the minibatch for training set and testing set\n",
        "trainset_batchsize = trainloader.batch_size\n",
        "testset_batchsize = testloader.batch_size\n",
        "# Print sizes of the minibatch\n",
        "print(trainset_batchsize,testset_batchsize)"
      ],
      "metadata": {
        "id": "MdLZqninNcb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the class Net\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):    \n",
        "    \t# Define all the parameters of the net\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28 * 1, 200)\n",
        "        self.fc2 = nn.Linear(200,10)\n",
        "\n",
        "    def forward(self, x):   \n",
        "    \t# Do the forward pass\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "0EZxjPNONeP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the Adam optimizer and Cross-Entropy loss function\n",
        "model = Net()   \n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "  \n",
        "for batch_idx, data_target in enumerate(train_loader):\n",
        "    data = data_target[0]\n",
        "    target = data_target[1]\n",
        "    data = data.view(-1, 28 * 28)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Complete a forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Compute the loss, gradients and change the weights\n",
        "    loss = criterion(output,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "Tw_y_JpgNgr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model in eval mode\n",
        "model.eval()\n",
        "\n",
        "for i, data in enumerate(test_loader,0):\n",
        "    inputs, labels = data\n",
        "    \n",
        "    # Put each image into a vector\n",
        "    inputs = inputs.view(-1, 28*28)\n",
        "    \n",
        "    # Do the forward pass and get the predictions\n",
        "    outputs = model(inputs)\n",
        "    _, outputs = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (outputs == labels).sum().item()\n",
        "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "RyX93ZvONi3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 10 random images of shape (1, 28, 28)\n",
        "images = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Build 6 conv. filters\n",
        "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Convolve the image with the filters \n",
        "output_feature = conv_filters(images)\n",
        "print(output_feature.shape)"
      ],
      "metadata": {
        "id": "qFOLBhfmNk7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create 10 random images\n",
        "image = torch.rand(10, 1, 28, 28)\n",
        "\n",
        "# Create 6 filters\n",
        "filters = torch.rand(6, 1, 3, 3)\n",
        "\n",
        "# Convolve the image with the filters\n",
        "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
        "print(output_feature.shape)"
      ],
      "metadata": {
        "id": "J0-OLlISNtJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "max_pooling = torch.nn.MaxPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = max_pooling(im)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.max_pool2d(im, 2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ],
      "metadata": {
        "id": "Ugi9pTlmNwII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a pooling operator with size `2`.\n",
        "avg_pooling = torch.nn.AvgPool2d(2)\n",
        "\n",
        "# Apply the pooling operator\n",
        "output_feature = avg_pooling(im)\n",
        "\n",
        "# Use pooling operator in the image\n",
        "output_feature_F = F.avg_pool2d(im,2)\n",
        "\n",
        "# print the results of both cases\n",
        "print(output_feature)\n",
        "print(output_feature_F)"
      ],
      "metadata": {
        "id": "kWFPveEuNwtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = nn.Linear(10*7*7, 10)"
      ],
      "metadata": {
        "id": "SckFV5fuN0u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "\t\t\n",
        "        # Instantiate the ReLU nonlinearity\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # Instantiate two convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Instantiate a max pooling layer\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Instantiate a fully connected layer\n",
        "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Apply conv followd by relu, then in next line pool\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # Prepare the image for the fully connected layer\n",
        "        x = x.view(-1, 7*7*10)\n",
        "\n",
        "        # Apply the fully connected layer and return the result\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "T4yjeLkjN1K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Compute the forward pass\n",
        "    outputs = net(inputs)\n",
        "        \n",
        "    # Compute the loss function\n",
        "    loss = criterion(outputs,labels)\n",
        "        \n",
        "    # Compute the gradients\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update the weights\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "YtdnG2KZN5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the data in the test_loader\n",
        "for i, data in enumerate(test_loader):\n",
        "  \n",
        "    # Get the image and label from data\n",
        "    image, label = data\n",
        "    \n",
        "    # Make a forward pass in the net with your image\n",
        "    output = net(image)\n",
        "    \n",
        "    # Argmax the results of the net\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "    if predicted == label:\n",
        "        print(\"Yipes, your net made the right prediction \" + str(predicted))\n",
        "    else:\n",
        "        print(\"Your net prediction was \" + str(predicted) + \", but the correct label is: \" + str(label))"
      ],
      "metadata": {
        "id": "ETnmIuhkN57B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Declare all the layers for feature extraction\n",
        "        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \n",
        "                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\n",
        "                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))"
      ],
      "metadata": {
        "id": "ICbCLsQCN8Bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Declare all the layers for feature extraction\n",
        "        self.features = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \n",
        "                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                      nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\n",
        "                                      nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\n",
        "        \n",
        "        # Declare all the layers for classification\n",
        "        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024), nn.ReLU(inplace=True),\n",
        "                                       \tnn.Linear(1024, 2048), nn.ReLU(inplace=True),\n",
        "                                        nn.Linear(2048, 10))\n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        # Apply the feature extractor in the input\n",
        "        x = self.features(x)\n",
        "        \n",
        "        # Squeeze the three spatial dimensions in one\n",
        "        x = x.view(-1, 7 * 7 * 40)\n",
        "        \n",
        "        # Classify the images\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pvU2BLF6N-y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the indices\n",
        "indices = np.arange(60000)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Build the train loader\n",
        "train_loader = torch.utils.data.DataLoader(datasets.MNIST('mnist', download=True, train=True,\n",
        "                     transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                     batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[:55000]))\n",
        "\n",
        "# Build the validation loader\n",
        "val_loader = torch.utils.data.DataLoader(datasets.MNIST('mnist', download=True, train=True,\n",
        "                   transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])),\n",
        "                   batch_size=64, shuffle=False, sampler=torch.utils.data.SubsetRandomSampler(indices[55000:]))"
      ],
      "metadata": {
        "id": "eaOasSwnOA37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the network\n",
        "model = Net()\n",
        "\n",
        "# Instantiate the cross-entropy loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Instantiate the Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay=0.001)"
      ],
      "metadata": {
        "id": "s6FXraxkODId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        \n",
        "        # Define all the parameters of the net\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(28*28, 200),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(200,500),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(500,10))"
      ],
      "metadata": {
        "id": "T6oWTjVZOGnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Implement the sequential module for feature extraction\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(10),\n",
        "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, stride=1, padding=1),\n",
        "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True), nn.BatchNorm2d(20))\n",
        "        \n",
        "        # Implement the fully connected layer for classification\n",
        "        self.fc = nn.Linear(in_features=7*7*20, out_features=10)"
      ],
      "metadata": {
        "id": "WEsXnuvjOLQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model\n",
        "model = Net()\n",
        "\n",
        "# Change the number of out channels\n",
        "model.fc = nn.Linear(7 * 7 * 512, 26)\n",
        "\n",
        "# Train and evaluate the model\n",
        "model.train()\n",
        "train_net(model, optimizer, criterion)\n",
        "print(\"Accuracy of the net is: \" + str(model.eval()))"
      ],
      "metadata": {
        "id": "sS5Ak97aON-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the module\n",
        "import torchvision\n",
        "\n",
        "# Download resnet18\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all the layers bar the last one\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Change the number of output units\n",
        "model.fc = nn.Linear(512,7)"
      ],
      "metadata": {
        "id": "io1_Qf3gOQnN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}